{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98c2145d",
   "metadata": {},
   "source": [
    "# Master Comparison Experiments\n",
    "This notebook compares a suite of classical models and an MLP across curated training datasets and a shared general test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901d4d9c",
   "metadata": {},
   "source": [
    "## Workflow\n",
    "1. Configure paths and helper utilities.\n",
    "2. Load and align training datasets with the shared general test distribution.\n",
    "3. Train baseline models and record timing and accuracy metrics.\n",
    "4. Aggregate and persist comparison results for downstream analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e0558c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4557a883",
   "metadata": {},
   "source": [
    "## Dataset Configuration\n",
    "Define dataset sources and reproducibility constants. Update the dataset list as new feature collections become available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783dc0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "NOTEBOOK_DIR = Path.cwd()\n",
    "DATASETS = [\n",
    "    (\"20_bins\", Path(\"../data/20_bins/20_bins_training_data.csv\")),\n",
    "    (\"20_bins_all\", Path(\"../data/20_bins_all/20_bins_all_training_data.csv\")),\n",
    "    (\"20_bins_distortion\", Path(\"../data/20_bins_distortion/20_bins_distortion_training_data.csv\")),\n",
    "    (\"20_bins_energy\", Path(\"../data/20_bins_energy/20_bins_energy_training_data.csv\")),\n",
    "    (\"20_bins_shape\", Path(\"../data/20_bins_shape/20_bins_shape_training_data.csv\")),\n",
    "    (\"40_bins\", Path(\"../data/40_bins/40_bins_training_data.csv\")),\n",
    "    (\"60_bins\", Path(\"../data/60_bins/60_bins_training_data.csv\")),\n",
    "]\n",
    "GENERAL_TEST_PATH = Path(\"../data/test_data/test_data.csv\")\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1cca33",
   "metadata": {},
   "source": [
    "## Load General Test Distribution\n",
    "Load the shared evaluation dataset once so each experiment reuses a consistent reference split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29812cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "general_test_df = pd.read_csv(GENERAL_TEST_PATH)\n",
    "general_feature_df = general_test_df.drop(columns=[\"label\"])\n",
    "general_y = general_test_df[\"label\"]\n",
    "general_feature_columns = list(general_feature_df.columns)\n",
    "\n",
    "print(\n",
    "    f\"[INFO] General test dataset loaded with {general_test_df.shape[0]} rows and \"\n",
    "    f\"{general_feature_df.shape[1]} feature columns.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95669c4a",
   "metadata": {},
   "source": [
    "## Model Factory\n",
    "Instantiate fresh scikit-learn models for every dataset to avoid cross-contamination of learned parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12ae931",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_models(random_state: int = RANDOM_STATE) -> dict[str, object]:\n",
    "    \"\"\"Return the suite of models to benchmark.\"\"\"\n",
    "    return {\n",
    "        \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "        \"Support Vector Machine\": SVC(kernel=\"rbf\", gamma=\"scale\"),\n",
    "        \"Random Forest\": RandomForestClassifier(n_estimators=200, random_state=random_state, n_jobs=-1),\n",
    "        \"Gradient Boosting\": GradientBoostingClassifier(random_state=random_state),\n",
    "        \"MLP Classifier\": MLPClassifier(hidden_layer_sizes=(128, 64), max_iter=500, random_state=random_state),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01dd6336",
   "metadata": {},
   "source": [
    "## Train And Evaluate\n",
    "Iterate through each dataset, scale features, train every model, and capture accuracy metrics with timing information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac5e31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for dataset_name, dataset_path in DATASETS:\n",
    "    dataset_df = pd.read_csv(dataset_path)\n",
    "    feature_columns = [col for col in dataset_df.columns if col != \"label\"]\n",
    "    shared_columns = [col for col in feature_columns if col in general_feature_columns]\n",
    "\n",
    "    X = dataset_df[shared_columns]\n",
    "    y = dataset_df[\"label\"]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X,\n",
    "        y,\n",
    "        test_size=TEST_SIZE,\n",
    "        random_state=RANDOM_STATE,\n",
    "        stratify=y,\n",
    "    )\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    general_X_subset = general_feature_df[shared_columns]\n",
    "    general_X_scaled = scaler.transform(general_X_subset)\n",
    "\n",
    "    models = build_models()\n",
    "    for model_name, model in models.items():\n",
    "        start_time = time.time()\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "\n",
    "        training_time = time.time() - start_time\n",
    "\n",
    "        train_accuracy = accuracy_score(y_train, model.predict(X_train_scaled))\n",
    "        test_accuracy = accuracy_score(y_test, model.predict(X_test_scaled))\n",
    "        general_accuracy = accuracy_score(general_y, model.predict(general_X_scaled))\n",
    "\n",
    "        results.append(\n",
    "            {\n",
    "                \"Dataset\": dataset_name,\n",
    "                \"Model\": model_name,\n",
    "                \"Train Accuracy\": train_accuracy,\n",
    "                \"Test Accuracy\": test_accuracy,\n",
    "                \"General Test Accuracy\": general_accuracy,\n",
    "                \"Training Time (s)\": training_time,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    print(f\"[INFO] Completed training for {dataset_name}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e602289f",
   "metadata": {},
   "source": [
    "## Results\n",
    "Sort by general test accuracy, display the table, and persist the summary for downstream analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0f60e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "formatted_df = results_df.copy()\n",
    "numeric_columns = [\n",
    "    \"Train Accuracy\",\n",
    "    \"Test Accuracy\",\n",
    "    \"General Test Accuracy\",\n",
    "    \"Training Time (s)\",\n",
    "]\n",
    "\n",
    "formatted_df[numeric_columns] = formatted_df[numeric_columns].round(4)\n",
    "\n",
    "sorted_results = formatted_df.sort_values(by=\"General Test Accuracy\", ascending=False)\n",
    "display(sorted_results)\n",
    "print(sorted_results.to_string(index=False))\n",
    "\n",
    "output_path = NOTEBOOK_DIR / \"model_experiments\" / \"model_performance_summary.csv\"\n",
    "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "sorted_results.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"[INFO] Saved results to {output_path.resolve()}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
